{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb779899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8bef3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transactions = pd.read_csv(\"../ieee_fraud_data/train_transaction.csv\")\n",
    "test_transactions = pd.read_csv(\"../ieee_fraud_data/test_transaction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b2ce4c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pd.read_csv(\"../ieee_fraud_data/test_transaction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "eb2e6ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = t1[\"TransactionID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6279ea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TransactionDT seems to be in seconds, we can transform to days\n",
    "train_transactions[\"TransactionDay\"] = (train_transactions[\"TransactionDT\"]/86400).astype(int)\n",
    "test_transactions[\"TransactionDay\"] = (test_transactions[\"TransactionDT\"]/86400).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f304c7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_transactions[\"isFraud\"].copy()\n",
    "train_transactions = train_transactions.drop(columns=[\"isFraud\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1a03ba",
   "metadata": {},
   "source": [
    "##### What features to drop first ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59aaee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transactions[[\"dist1\", \"dist2\"]].isna().sum()/len(train_transactions)\n",
    "# This yields dist1, dist2 having > 50% of values NA, will drop them completely\n",
    "train_transactions = train_transactions.drop(columns=[\"dist1\", \"dist2\"])\n",
    "test_transactions = test_transactions.drop(columns=[\"dist1\", \"dist2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1a74f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transactions[[f\"M{i}\" for i in range(1, 10)]].isna().sum()/len(train_transactions)\n",
    "# This yields M7, M8, M9 having > 50% of values NA, will drop them completely\n",
    "train_transactions = train_transactions.drop(columns=[\"M7\", \"M8\", \"M9\"])\n",
    "test_transactions = test_transactions.drop(columns=[\"M7\", \"M8\", \"M9\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b11fb902",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transactions[[f\"D{i}\" for i in range(1, 16)]].isna().sum()/len(train_transactions)\n",
    "# This yields D5, D6, D7, D8, D9, D12, D13, D14 having > 50% of values NA, will drop them completely\n",
    "train_transactions = train_transactions.drop(columns=[\"D5\", \"D6\", \"D7\", \"D8\", \"D9\", \"D12\", \"D13\", \"D14\"])\n",
    "test_transactions = test_transactions.drop(columns=[\"D5\", \"D6\", \"D7\", \"D8\", \"D9\", \"D12\", \"D13\", \"D14\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7db06649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V* columns are too many and would take ages to figure things out. First thing we could try is\n",
    "# to try running PCA and reduce the dimension, but will refrain from this unless the rest of the\n",
    "# features are completely useless\n",
    "train_transactions = train_transactions.drop(columns=[f\"V{i}\" for i in range(1, 340)])\n",
    "test_transactions = test_transactions.drop(columns=[f\"V{i}\" for i in range(1, 340)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a8ee408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TransactionID', 'isFraud', 'TransactionDT', 'TransactionAmt',\n",
       "       'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6',\n",
       "       'addr1', 'addr2', 'P_emaildomain', 'R_emaildomain', 'C1', 'C2', 'C3',\n",
       "       'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14',\n",
       "       'D1', 'D2', 'D3', 'D4', 'D10', 'D11', 'D15', 'M1', 'M2', 'M3', 'M4',\n",
       "       'M5', 'M6', 'TransactionDay', 'card1_addr1',\n",
       "       'card1_addr1_P_emaildomain'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transactions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c287f297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(train, test, column):\n",
    "    all_labels, _ = pd.concat([train[column], test[column]], axis=0).factorize(sort=True)\n",
    "    \n",
    "    train[column] = all_labels[:len(train)].astype(int)\n",
    "    test[column] = all_labels[len(train):].astype(int)\n",
    "\n",
    "def frequency_encode(train, test, columns):\n",
    "    # Apparently this gives good results in lots of kaggle competitions\n",
    "    # I couldn't find much online why the frequency is actually useful\n",
    "    # as a feature. My intuition is that the model might match low or\n",
    "    # high frequencies with card fraud in a case or another. Eg. if \n",
    "    # most of the frauds are coming from a certain email domain, the\n",
    "    # frequency is going to be a useful feature.\n",
    "    n = len(train) + len(test)\n",
    "    for column in columns:\n",
    "        f = (pd.concat(\n",
    "                [train[column], test[column]], axis=0\n",
    "            ).value_counts(dropna=True)/n).to_dict()    \n",
    "        train[f\"{column}_FE\"] = train[column].map(f).astype(float)\n",
    "        test[f\"{column}_FE\"] = test[column].map(f).astype(float)\n",
    "\n",
    "def concatenate(train, test, col1, col2):\n",
    "    new_name = f\"{col1}_{col2}\"\n",
    "    train[new_name] = train[col1].astype(str)+ \"_\" + train[col2].astype(str)\n",
    "    test[new_name] = test[col1].astype(str) + \"_\" + test[col2].astype(str)\n",
    "    \n",
    "    encode_labels(train, test, new_name)\n",
    "    \n",
    "\n",
    "def groupby(train, test, index, column, aggregation):\n",
    "    # We want for example, the mean transaction value for every card1_address1 pair\n",
    "    new_name = f\"{column}_{index}_{aggregation}\"\n",
    "    \n",
    "    f = pd.concat([train[[index, column]], test[[index, column]]])\n",
    "    f = f.groupby([index])[column].agg([aggregation]).reset_index().rename(columns={aggregation: new_name})\n",
    "    f.index = list(f[index])\n",
    "    f = f[new_name].to_dict()\n",
    "    train[new_name] = train[index].map(f).astype(float)\n",
    "    test[new_name] = train[index].map(f).astype(float)\n",
    "    train[new_name].fillna(-1, inplace=True)\n",
    "    test[new_name].fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b6e693a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card1</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>addr1</th>\n",
       "      <th>P_emaildomain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13926</td>\n",
       "      <td>68.5</td>\n",
       "      <td>315.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55544</th>\n",
       "      <td>13926</td>\n",
       "      <td>40.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263717</th>\n",
       "      <td>13926</td>\n",
       "      <td>317.5</td>\n",
       "      <td>315.0</td>\n",
       "      <td>comcast.net</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        card1  TransactionAmt  addr1 P_emaildomain\n",
       "0       13926            68.5  315.0           NaN\n",
       "55544   13926            40.0  315.0     gmail.com\n",
       "263717  13926           317.5  315.0   comcast.net"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transactions[train_transactions[\"card1_addr1\"] == 13832][[\"card1\", \"TransactionAmt\", \"addr1\", \"P_emaildomain\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2e82ef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transactions = train_transactions.drop(columns=[\"TransactionID\", \"TransactionDT\"])\n",
    "test_transactions = test_transactions.drop(columns=[\"TransactionID\", \"TransactionDT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d554a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate(train_transactions, test_transactions, 'card1','addr1')\n",
    "concatenate(train_transactions, test_transactions, \"card1_addr1\", \"P_emaildomain\")\n",
    "frequency_encode(train_transactions, test_transactions, ['addr1','card1','card2','card3','P_emaildomain'])\n",
    "\n",
    "groupby(train_transactions, test_transactions, \"card1\", \"TransactionAmt\", \"mean\")\n",
    "groupby(train_transactions, test_transactions, \"card1\", \"TransactionAmt\", \"std\")\n",
    "groupby(train_transactions, test_transactions, \"card1_addr1\", \"TransactionAmt\", \"mean\")\n",
    "groupby(train_transactions, test_transactions, \"card1_addr1\", \"TransactionAmt\", \"std\")\n",
    "groupby(train_transactions, test_transactions, \"card1_addr1_P_emaildomain\", \"TransactionAmt\", \"mean\")\n",
    "groupby(train_transactions, test_transactions, \"card1_addr1_P_emaildomain\", \"TransactionAmt\", \"std\")\n",
    "\n",
    "groupby(train_transactions, test_transactions, \"card1\", \"D11\", \"mean\")\n",
    "groupby(train_transactions, test_transactions, \"card1\", \"D11\", \"std\")\n",
    "groupby(train_transactions, test_transactions, \"card1_addr1\", \"D11\", \"mean\")\n",
    "groupby(train_transactions, test_transactions, \"card1_addr1\", \"D11\", \"std\")\n",
    "groupby(train_transactions, test_transactions, \"card1_addr1_P_emaildomain\", \"D11\", \"mean\")\n",
    "groupby(train_transactions, test_transactions, \"card1_addr1_P_emaildomain\", \"D11\", \"std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "61ef9423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "id": "41d02e79",
   "metadata": {},
   "source": [
    "#TODO figure out what to do with these\n",
    "train_transactions = train_transactions.drop(columns=[\n",
    "    \"ProductCD\", \"M1\", \"M2\", \"M3\", \"M4\", \"M5\", \"M6\", \"P_emaildomain\", \"R_emaildomain\", \"card4\", \"card5\", \"card6\"]\n",
    ")\n",
    "test_transactions = test_transactions.drop(columns=[\n",
    "    \"ProductCD\", \"M1\", \"M2\", \"M3\", \"M4\", \"M5\", \"M6\", \"P_emaildomain\", \"R_emaildomain\", \"card4\", \"card5\", \"card6\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c961d60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionAmt                                        0\n",
       "card1                                                 0\n",
       "card2                                              8933\n",
       "card3                                              1565\n",
       "addr1                                             65706\n",
       "addr2                                             65706\n",
       "C1                                                    0\n",
       "C2                                                    0\n",
       "C3                                                    0\n",
       "C4                                                    0\n",
       "C5                                                    0\n",
       "C6                                                    0\n",
       "C7                                                    0\n",
       "C8                                                    0\n",
       "C9                                                    0\n",
       "C10                                                   0\n",
       "C11                                                   0\n",
       "C12                                                   0\n",
       "C13                                                   0\n",
       "C14                                                   0\n",
       "D1                                                 1269\n",
       "D2                                               280797\n",
       "D3                                               262878\n",
       "D4                                               168922\n",
       "D10                                               76022\n",
       "D11                                              279287\n",
       "D15                                               89113\n",
       "TransactionDay                                        0\n",
       "card1_addr1                                           0\n",
       "card1_addr1_P_emaildomain                             0\n",
       "addr1_FE                                          65706\n",
       "card1_FE                                              0\n",
       "card2_FE                                           8933\n",
       "card3_FE                                           1565\n",
       "P_emaildomain_FE                                  94456\n",
       "TransactionAmt_card1_addr1_mean                       0\n",
       "TransactionAmt_card1_mean                             0\n",
       "TransactionAmt_card1_std                              0\n",
       "TransactionAmt_card1_addr1_std                        0\n",
       "TransactionAmt_card1_addr1_P_emaildomain_mean         0\n",
       "TransactionAmt_card1_addr1_P_emaildomain_std          0\n",
       "D11_card1_mean                                        0\n",
       "D11_card1_std                                         0\n",
       "D11_card1_addr1_mean                                  0\n",
       "D11_card1_addr1_std                                   0\n",
       "D11_card1_addr1_P_emaildomain_mean                    0\n",
       "D11_card1_addr1_P_emaildomain_std                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transactions.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "40d44d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxT = train_transactions.index[:3*len(train_transactions)//4]\n",
    "idxV = test_transactions.index[3*len(test_transactions)//4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "dc42b72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HistGradientBoostingClassifier(learning_rate=0.02, max_depth=12)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = HistGradientBoostingClassifier(\n",
    "    #n_estimators=2000,\n",
    "    max_depth=12,\n",
    "    learning_rate=0.02, \n",
    "    #subsample=0.8,\n",
    "#     colsample_bytree=0.4, \n",
    "#     missing=-1, \n",
    "#    eval_metric='auc'\n",
    ")\n",
    "xgb.fit(train_transactions.loc[idxT], y_train[idxT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a8f96d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9712172286122536"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.score(train_transactions.loc[idxV],y_train[idxV])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e4c995ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = xgb.predict(test_transactions)\n",
    "prediction = pd.DataFrame({\"isFraud\": xgb.predict(test_transactions), \"TransactionId\": t1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "18b603a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.to_csv(\"result.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
